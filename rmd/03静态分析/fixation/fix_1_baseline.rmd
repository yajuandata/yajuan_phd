---
title: "fix相关静态分析1"
output: html_document
date: "2023-09-06"
---
摘要：计算fix相关的静态差异

加载包
```{r} 
library(tidyverse)
library(readxl)
library(data.table)
library(furrr)
plan(multisession(workers = 5))
```

定义处理方法
```{r, echo=FALSE, message=FALSE}
# 定义方法，对fixation数据进行统计处理
fixation_ss <- function(dt_path, loss_path, words_path, baseline_type_path, block_info_path) {
  # 读取loss数据，字数数据，fixation数据, 维度与block关系信息
  loss_info <- fread(loss_path)

  dt_word <- read_excel(words_path) %>%
    select(pic, words_yuduan, words_question, words)

  dt_a <- fread(dt_path) %>%
    mutate_at(vars(12:24), as.numeric) %>%
    anti_join(loss_info, by = c("participants", "pic")) %>%
    filter(stim == "baseline") %>%
    rename(base_type = type)

  dt_a <- dt_a %>%
    filter(eye == unique(dt_a$eye)[1])

  base_line_type <- read_excel(baseline_type_path) %>%
    select(block, baseline_type)

  block_info <- read_excel(block_info_path) %>%
    select(block, weidu) %>%
    rename(type = weidu) %>%
    left_join(base_line_type, by = "block") %>%
    drop_na()

  # 合并数据与维度与block关系信息
  dt_a <- dt_a %>%
    left_join(block_info, by = "block")

  # 判断dt_a是否为空，如果为空则返回空值，不为空则执行后续计算
  if (nrow(dt_a) == 0) {
    return(dt_a)
  } else {
    # 根据维度计算fixation_duration和fixation_ps的平均值，每字平均注视次数，合并，删除中间数据
    dt_a_s <- dt_a %>%
      group_by(type, baseline_type) %>%
      reframe(fixation_duration = mean(dur), fixation_ps = mean(aps)) %>%
      mutate(participants = dt_a$participants[[1]], AOI = "overall")

    dt_a_s2 <- dt_a %>%
      group_by(type, baseline_type, pic) %>%
      left_join(dt_word, by = "pic") %>%
      reframe(fixation_count = n(), words = mean(words)) %>%
      mutate(fixation_per_word = fixation_count / words) %>%
      select(-words, -fixation_count) %>%
      group_by(type, baseline_type) %>%
      reframe(fixation_per_word = mean(fixation_per_word)) %>%
      mutate(participants = dt_a$participants[[1]], AOI = "overall") %>%
      left_join(dt_a_s)

    rm(dt_a_s)

    # 根据刺激类型和AOI对数据进行变形，合并，删除中间数据
    dt_yes <- dt_a %>%
      filter(stim %in% c("baseline", "target1", "target1_g")) %>%
      pivot_longer(12:15, names_to = "AOI", values_to = "hit") %>%
      filter(hit == 1) %>%
      select(1:11, type, baseline_type, AOI)

    dt_17 <- dt_a %>%
      filter(stim %in% c("target2", "target2_g", "target3", "target3_g", "target4", "target4_g")) %>%
      pivot_longer(cols = (12:13 | 18:24), names_to = "AOI", values_to = "hit") %>%
      filter(hit == 1) %>%
      select(1:11, type, baseline_type, AOI)

    dt_fixation <- dt_a %>%
      filter(stim %in% c("fixation", "fixation2", "fixation_g")) %>%
      pivot_longer(16:17, names_to = "AOI", values_to = "hit") %>%
      filter(hit == 1) %>%
      select(1:11, type, baseline_type, AOI)

    dt_aoi <- bind_rows(dt_yes, dt_17, dt_fixation)

    rm(dt_yes, dt_17, dt_fixation)

    # 对字数信息进行变形
    dt_word2 <- dt_word %>%
      select(-words) %>%
      pivot_longer(cols = 2:3, names_to = "AOI", values_to = "words") %>%
      mutate(AOI = str_replace_all(AOI, c("words_yuduan" = "yuduan", "words_question" = "question")))

    # 根据AOI计算fixation_duration和fixation_ps的平均值，每字平均注视次数，合并，删除中间数据
    dt_aoi_s <- dt_aoi %>%
      group_by(type, baseline_type, AOI) %>%
      reframe(fixation_duration = mean(dur), fixation_ps = mean(aps)) %>%
      mutate(participants = dt_a$participants[[1]])

    dt_aoi_s2 <- dt_aoi %>%
      group_by(type, baseline_type, pic, AOI) %>%
      reframe(fixation_count = n()) %>%
      left_join(dt_word2, by = c("pic", "AOI")) %>%
      mutate(words = case_when(is.na(words) ~ 1, .default = words)) %>%
      mutate(fixation_per_word = fixation_count / words) %>%
      select(-words, -fixation_count) %>%
      group_by(type, baseline_type, AOI) %>%
      reframe(fixation_per_word = mean(fixation_per_word)) %>%
      mutate(participants = dt_a$participants[[1]]) %>%
      left_join(dt_aoi_s)

    rm(dt_aoi_s)

    dt_fixation_summary <- bind_rows(dt_a_s2, dt_aoi_s2)

    # 删除其余中间数据
    rm(dt_word, dt_word2, dt_a, dt_aoi, loss_info, dt_a_s2, dt_aoi_s2, base_line_type, block_info)

    return(dt_fixation_summary)
  }
}
# 定义方法，接收一个文件夹目录，一个loss文件路径，一个字数文件路径, 一个基线类型文件路径，一个block信息为难路径，对文件夹下的全部数据文件通过fixation_ss函数进行处理，返回一个合并的数据。
fixation_ss_all <- function(path, loss_path, words_path, baseline_type_path, block_info_path) {
  # 获取文件夹下的全部文件路径
  file_list <- list.files(path, full.names = TRUE)

  # 对文件夹下的全部数据文件进行处理，循环报错数据进行跳过处理


  dt_fixation_summary <- file_list %>%
    future_map_dfr(fixation_ss, loss_path = loss_path, words_path = words_path, baseline_type_path = baseline_type_path, block_info_path = block_info_path)

  # 返回处理结果
  dt_fixation_summary
}
```

批量进行处理
```{r, echo=FALSE, message=FALSE}
# 定义文件夹路径，loss文件路径，字数文件路径
path <- "../yajuan_data/out/fix2_AOI_type"
loss_path <- "../yajuan_data/out/loss_rate_all/pic_list.csv"
words_path <- "info/count1.xlsx"
block_info_path <- "info/target_type.xlsx"
baseline_type_path <- "info/baseline_type.xlsx"

# 新建一个文件夹，用于存放处理后的数据
dir.create("../yajuan_data/statics")
dir.create("../yajuan_data/statics/fixation")

# 定义处理结果的保存路径
save_path <- "../yajuan_data/statics/fixation/fixation_01_baseline.csv"

# 对文件夹下的全部数据文件进行处理
dt_fixation_summary <- fixation_ss_all(path, loss_path, words_path, baseline_type_path, block_info_path) %>%
  arrange(participants, type, AOI) %>%
  select(participants, type, baseline_type, AOI, fixation_duration, fixation_ps, fixation_per_word)

# 保存处理结果
fwrite(dt_fixation_summary, save_path, na = "NA")
```



